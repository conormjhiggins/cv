This is where you enter all of your CV entries. Each entry should have a section identifier, whether to include in resume, a title, location, institution, start/end dates, and up to 3 description bullets.
section,in_resume,title,loc,institution,start,end,description_1,description_2,description_3
education,TRUE,MSc Statistics,Lancaster,Lancaster University,2018,2019,"Merit awarded. [Dissertation: 'Dynamic Bayesian models for predicting Premier League Football outcomes'](https://github.com/conormjhiggins/masters-dissertation/blob/main/masters_dissertation.pdf), applying advanced Bayesian statistical modelling to sports performance data.",,
education,TRUE,BSc Mathematics with Statistics,Lancaster,Lancaster University,2015,2018,"Strong quantitative foundation in statistics, probability and mathematical modelling; minor in Chemistry.",,
industry_positions,TRUE,Senior Analytics Engineer,Remote,Deliveroo,2025,Current,"Built and owned the Selection Intelligence platform end-to-end, a Snowflake and Python system ingesting ML pipeline outputs to map the global merchant universe across all Deliveroo markets, predict monthly merchant revenue, and surface high-value sales leads for the commercial sales team.","Drove significant Snowflake cost reduction and halved pipeline runtime from 4+ hours to under 2 hours through systematic refactoring of hundreds of models, full mart modelling of the team's domain, and targeted compute optimisations.","Championed AI tooling adoption across the Analytics Engineering function, producing practical guides and running workshops on Claude and Cursor for analysts and stakeholders; serve as escalation on-call engineer for major data incidents."
industry_positions,TRUE,Analytics Engineer,London,Deliveroo,2022,2025,"Served as lead Analytics Engineer for the restaurant domain, taking full ownership of the data infrastructure including ELT pipelines, dimensional models and the reporting layer powering daily commercial decision-making across all Deliveroo markets.","Drove cross-functional partnerships with Sales, Science and Product teams, maintaining the data infrastructure powering Deliveroo's most critical Looker dashboards for senior stakeholders.","Built and maintained production ELT pipelines using Deliveroo's in-house orchestration framework; developed Python tooling for pipeline automation, data quality testing and output validation."
industry_positions,TRUE,Analytics Engineer,London,DAZN,2020,2022,"Designed and built DAZN's first payments data warehouse from scratch using Snowflake and Airflow, establishing the company's only source of truth for Invoices, Transactions and Involuntary Churn reporting across a rapidly scaling global streaming platform.","Built and maintained scalable ELT pipelines using dbt, Airflow and Python; partnered with PMs and stakeholders to deliver data-led insights informing key product and commercial decisions.","Built the foundational data infrastructure used across the entire business, partnering with Finance and Product to deliver accurate payments reporting for a company with no prior data structure in this domain."
